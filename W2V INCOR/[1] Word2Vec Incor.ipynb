{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word2Vec** é um método para gerar *Word Embeddings* a partir de um corpus de texto, utilizando redes neurais.\n",
    "\n",
    "Desenvolvido por Tomas Mikolov *et al.* (Google) em 2013, é um dos métodos de geração de *word embeddings* mais populares em tarefas de processamento de linguagem natural (PLN) como análise de sentimento, tradução de textos e reconhecimento de entidades nomeadas (NER).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 1 - importanto as bibliotecas\n",
    "Vamos primeiro instalar e importar as bibliotecas que utilizaremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\roger\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from gensim import corpora, models, similarities\n",
    "import nltk\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o pré-processamento em língua portuguesa, vamos usar o pacote ```pt_core_news_sm```. Instale antes com:\n",
    "    \n",
    "```python -m spacy download pt_core_news_sm```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('pt_core_news_sm') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passo 2 - Pré-processamento do *corpus*\n",
    "\n",
    "\n",
    "Vamos abrir o arquivo e transformá-lo em um *dataframe*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"incor.txt\", \"r\", encoding='ISO-8859-1')\n",
    "df = pd.DataFrame(file)\n",
    "df.columns = ['lines']\n",
    "df = df.sort_index()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim são os textos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;IDENTIFICACAO DO PACIENTE: 10000237&gt;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SEQUENCIA DO EVENTO: 3&gt;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;INTERVALO EM DIAS ENTRE OS EVENTOS: 77&gt;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28/08/2014\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040122</th>\n",
       "      <td>Retorno na vaga, com exames.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040123</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040124</th>\n",
       "      <td>R3 ######## ######\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040125</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040126</th>\n",
       "      <td>Solicitei: COLESTEROL (SANGUE); CREATININA / ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040127 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     lines\n",
       "0                  <IDENTIFICACAO DO PACIENTE: 10000237>\\n\n",
       "1                               <SEQUENCIA DO EVENTO: 3>\\n\n",
       "2               <INTERVALO EM DIAS ENTRE OS EVENTOS: 77>\\n\n",
       "3                                                       \\n\n",
       "4                                             28/08/2014\\n\n",
       "...                                                    ...\n",
       "1040122                     Retorno na vaga, com exames.\\n\n",
       "1040123                                                 \\n\n",
       "1040124                               R3 ######## ######\\n\n",
       "1040125                                                 \\n\n",
       "1040126   Solicitei: COLESTEROL (SANGUE); CREATININA / ...\n",
       "\n",
       "[1040127 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos primeiro remover os acentos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accents(text):\n",
    "    '''Strip accents out.'''\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', text)\n",
    "                   if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "clean2 = lambda x: cleaning1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df.lines.apply(remove_accents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;IDENTIFICACAO DO PACIENTE: 10000237&gt;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;SEQUENCIA DO EVENTO: 3&gt;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;INTERVALO EM DIAS ENTRE OS EVENTOS: 77&gt;\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28/08/2014\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040122</th>\n",
       "      <td>Retorno na vaga, com exames.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040123</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040124</th>\n",
       "      <td>R3 ######## ######\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040125</th>\n",
       "      <td>\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040126</th>\n",
       "      <td>Solicitei: COLESTEROL (SANGUE); CREATININA / ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1040127 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     lines\n",
       "0                  <IDENTIFICACAO DO PACIENTE: 10000237>\\n\n",
       "1                               <SEQUENCIA DO EVENTO: 3>\\n\n",
       "2               <INTERVALO EM DIAS ENTRE OS EVENTOS: 77>\\n\n",
       "3                                                       \\n\n",
       "4                                             28/08/2014\\n\n",
       "...                                                    ...\n",
       "1040122                     Retorno na vaga, com exames.\\n\n",
       "1040123                                                 \\n\n",
       "1040124                               R3 ######## ######\\n\n",
       "1040125                                                 \\n\n",
       "1040126   Solicitei: COLESTEROL (SANGUE); CREATININA / ...\n",
       "\n",
       "[1040127 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, vamos limpar, usando expressões regulares, tudo que não é caracter alfanumérico e passar tudo para caixa baixa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['lines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x0000020EBB931820>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brief_cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos lematizar e retirar as *stopwords*, para diminuir a dimensionalidade, com a biblioteca ```spacy```. Vamos usar ```spacy.pipe()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(doc):\n",
    "    # lematizar e retirar stopwords\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # como Word2Vec usa palavras de contexto para aprender a representação vetorial de uma palavra-alvo,\n",
    "    # se uma frase tiver apenas uma ou duas palavras,\n",
    "    # o benefício para o treinamento é muito pequeno    \n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_process=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  negar sincopar pra sincopar',\n",
       " '  negar edema mmii usar lasix mencionar restria ha drica l dia',\n",
       " '  negar perda ponderal',\n",
       " None,\n",
       " '  ef p est imc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt[681:686]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt2 = [str(row.strip()) for row in txt if (row != None and row.strip() != '.')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paciente encaminhar intersticio sianis sugestivo hp desproporcinal aumentar psp ano aumentar ca maras direito mov paradoxal septo alar paciente internar recentemente reumatologia infea respiratio pôr imagem tomografia ta rax sugestivo progressa doena comparar mesmo internaa iniciar sildenafil mg h',\n",
       " 'atual cf iii referir melhorar internaa negar dor torar cica sincopar tontura']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt2[632:634]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos remover os valores faltantes e duplicados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>identificacao paciente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sequencia evento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intervalar dia evento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ambulaa rir sono</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rm ago ps diag enxertar c radial p dp cd mam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040115</th>\n",
       "      <td>lab hb leuco plt col hdl ldl trig cpk gli u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040118</th>\n",
       "      <td>trocar clortalidona mg xdia aumentar clonidina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040119</th>\n",
       "      <td>solicitar mapa retornar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040121</th>\n",
       "      <td>orientar caminhar cobrar retornar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040126</th>\n",
       "      <td>solicitar colesterol sangue creatinina sorar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284961 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     clean\n",
       "0                                   identificacao paciente\n",
       "1                                         sequencia evento\n",
       "2                                    intervalar dia evento\n",
       "6                                         ambulaa rir sono\n",
       "11         rm ago ps diag enxertar c radial p dp cd mam...\n",
       "...                                                    ...\n",
       "1040115    lab hb leuco plt col hdl ldl trig cpk gli u ...\n",
       "1040118  trocar clortalidona mg xdia aumentar clonidina...\n",
       "1040119                            solicitar mapa retornar\n",
       "1040121                  orientar caminhar cobrar retornar\n",
       "1040126    solicitar colesterol sangue creatinina sorar...\n",
       "\n",
       "[284961 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "674083"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigramas\n",
    "O pacote ```Gensim Phrases``` detecta automaticamente frases comuns (bigramas) de uma lista de frases.\n",
    "\n",
    "Veja mais em: https://radimrehurek.com/gensim/models/phrases.html\n",
    "\n",
    "Com o método ```Phrases()```, vamos criar frases relevantes a partir da lista de frases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "sent = [row.split() for row in df_clean['clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Phraser()``` reduz o consumo de memória de ```phrases``` ao descartar estado do modelo não necessário para a detecção de bigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos o corpus com base nos bigramas detectados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = bigram[sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Palavras frequentes\n",
    "Vamos calcular a frequencia das palavras, para verificar a eficácia da lematização, remoção de palavras irrelevantes e adição de bigramas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48183"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict \n",
    "\n",
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mg', 'comp', 'vos', 'xd', 'x', 'dia', 'negar', 'paciente', 'referir', 'usar']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 3 - Treinamento do modelo\n",
    "\n",
    "Hora de treinar nosso modelo Word2Vec com nossos dados. Primeiro, vamos verificar o ambiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "from time import time\n",
    "\n",
    "cores = multiprocessing.cpu_count() # conta o número de núcleos do computador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos parametrizar nosso modelo.\n",
    "\n",
    "- *min_count*: Ignora todas as palavras com frequência absoluta total inferior a esta\n",
    "- *window*: A distância máxima entre a palavra atual e a prevista em uma frase. Por exemplo, palavras da janela à esquerda e palavras da janela à esquerda do nosso alvo\n",
    "- *size*: Dimensionalidade dos vetores\n",
    "- *sample*: O limite para configurar quais palavras de alta frequência são reduzidas aleatoriamente\n",
    "- *alpha*: A taxa de aprendizagem inicial\n",
    "- *min_alpha*: A taxa de aprendizado cairá linearmente para *min_alpha* conforme o treinamento progride\n",
    "- *negative*: Se > 0, a amostragem negativa será usada, o int para negativo especifica quantas \"palavras de ruído\" devem ser eliminadas. Se definido como 0, nenhuma amostra negativa é usada\n",
    "- *workers*: Quantidade de *threads* de trabalho para treinar o modelo (treinamento mais rápido com máquinas multicore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=2,\n",
    "                     vector_size=32,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=10,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construindo o vocabulário e treinando o modelo\n",
    "Parâmetros do treinamento:\n",
    "\n",
    "*total_examples: Contagem de sentenças;\n",
    "*epochs*: Número de iterações (épocas) no corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(sentences, progress_per=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47035010, 86169630)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passo 4 - Salvando o modelo\n",
    "Vamos salvar o modelo nos formatos *KeyedVectors* e binário, para utilizarmos posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-bc56ad85d6ac>:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)  # deixa o modelo mais eficiente, pois não vamos mais treiná-lo futuramente\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)  # deixa o modelo mais eficiente, pois não vamos mais treiná-lo futuramente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"corpus_incor.model\")\n",
    "w2v_model.wv.save_word2vec_format('corpus_incor.bin', binary=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que já treinamos nosso modelo, [vamos ver aqui como utilizá-lo](https://github.com/lisaterumi/word2vec-harry-potter-portugues/blob/main/%5B2%5D%20tSNE-Harry-Potter.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
